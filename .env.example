# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
DEFAULT_MODEL=llama3

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# OpenAI Configuration (optional)
# OPENAI_API_KEY=your_openai_api_key_here

# Anthropic Configuration (optional)
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Gemini Configuration (optional)
# GEMINI_API_KEY=your_gemini_api_key_here
# GEMINI_MODEL=gemini-2.5-flash
